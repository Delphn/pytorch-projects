{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# get the device for training\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the nn class\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an instance of model\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1401,  0.0066, -0.0235,  0.0434,  0.0585,  0.0674,  0.0600,  0.0120,\n",
      "         -0.0213, -0.0087]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.1111, 0.0972, 0.0944, 0.1009, 0.1024, 0.1033, 0.1026, 0.0978, 0.0946,\n",
      "         0.0958]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Predicted class: tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28).to(device)\n",
    "logits = model(X)\n",
    "print(logits)\n",
    "pred_probab = torch.softmax(logits, dim=1)\n",
    "print(pred_probab)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f'Predicted class: {y_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "torch.Size([3, 784])\n",
      "torch.Size([3, 20])\n",
      "Before ReLU: tensor([[ 0.6567, -0.4206,  0.1905, -0.0107, -0.5304,  0.5004, -0.0896, -0.1603,\n",
      "         -0.3829,  0.2445, -0.4847,  0.2647,  0.6392,  0.1039, -0.0335, -0.5326,\n",
      "          0.3537,  0.3531,  0.3951, -0.1365],\n",
      "        [ 0.1953, -0.6316, -0.0978,  0.0490, -0.5422, -0.0218,  0.1268,  0.0297,\n",
      "         -0.4489,  0.1441, -0.6224,  0.3186,  0.7656, -0.0606, -0.2509, -0.0983,\n",
      "          0.1792,  0.4540,  0.3686,  0.0429],\n",
      "        [ 0.7368, -0.6552, -0.1588, -0.2888, -0.5384,  0.3615, -0.1741, -0.1942,\n",
      "         -0.4860,  0.2303, -0.6947,  0.2050,  0.4333, -0.0818, -0.1356, -0.3281,\n",
      "          0.2951,  0.2010,  0.3450,  0.2181]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.6567, 0.0000, 0.1905, 0.0000, 0.0000, 0.5004, 0.0000, 0.0000, 0.0000,\n",
      "         0.2445, 0.0000, 0.2647, 0.6392, 0.1039, 0.0000, 0.0000, 0.3537, 0.3531,\n",
      "         0.3951, 0.0000],\n",
      "        [0.1953, 0.0000, 0.0000, 0.0490, 0.0000, 0.0000, 0.1268, 0.0297, 0.0000,\n",
      "         0.1441, 0.0000, 0.3186, 0.7656, 0.0000, 0.0000, 0.0000, 0.1792, 0.4540,\n",
      "         0.3686, 0.0429],\n",
      "        [0.7368, 0.0000, 0.0000, 0.0000, 0.0000, 0.3615, 0.0000, 0.0000, 0.0000,\n",
      "         0.2303, 0.0000, 0.2050, 0.4333, 0.0000, 0.0000, 0.0000, 0.2951, 0.2010,\n",
      "         0.3450, 0.2181]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Model layers\n",
    "\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())\n",
    "\n",
    "# nn.Flatten layer\n",
    "# COnvert each 2D 28x28 image to a 1D 784-dimensional vector (minibatch dimension is maintained)\n",
    "\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())\n",
    "\n",
    "# nn.Linear layer\n",
    "# The linear layer applies a linear transformation on the input using its stored weights and biases\n",
    "\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())\n",
    "\n",
    "# nn.ReLU layer\n",
    "# Non-linear activations are what create the complex mappings between the modelâ€™s inputs and outputs. They are applied after linear transformations to introduce nonlinearity, helping neural networks learn a wide variety of phenomena\n",
    "\n",
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")\n",
    "\n",
    "# nn.Sequential\n",
    "# nn.Sequential is an ordered container of modules. The data is passed through all the modules in the same order as defined\n",
    "\n",
    "seq_modules = nn.Sequential(\n",
    "  flatten,\n",
    "  layer1,\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2cad8639a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(input_image[0].squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Softmax\n",
    "# The last linear layer of the neural network returns logits - raw values in [-infty, infty] - which are passed to the nn.Softmax module. The logits are scaled to values [0, 1] representing the modelâ€™s predicted probabilities for each class. dim parameter indicates the dimension along which the values must sum to 1.\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values: tensor([[-0.0014, -0.0325, -0.0115,  ...,  0.0122, -0.0171,  0.0032],\n",
      "        [-0.0291, -0.0338, -0.0295,  ...,  0.0165,  0.0063, -0.0151]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values: tensor([-0.0321, -0.0316], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values: tensor([[ 0.0110, -0.0183, -0.0277,  ..., -0.0436,  0.0222, -0.0304],\n",
      "        [-0.0092, -0.0376, -0.0334,  ..., -0.0057,  0.0249,  0.0360]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values: tensor([-0.0345,  0.0324], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values: tensor([[-0.0009, -0.0263, -0.0088,  ...,  0.0308, -0.0168,  0.0027],\n",
      "        [ 0.0274, -0.0110,  0.0277,  ..., -0.0368, -0.0246,  0.0307]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values: tensor([ 0.0423, -0.0255], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Parameters\n",
    "\n",
    "print(\"Module structure:\", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "  print(f\"Layer: {name} | Size: {param.size()} | Values: {param[:2]} \\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0d786df71ea4f07f0d88b79b83ebd172ea0b654c0fa3a183775c82d28b0ca8c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
